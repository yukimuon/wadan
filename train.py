# -*- coding: utf-8 -*-
"""Copy of train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ruhn_y-PHFkRFc0bqxyzozHogeNKcG3b
"""

import numpy as np
import matplotlib.pyplot as plt
import os
import cv2
from tqdm import tqdm
import pickle
import csv
import random
import tensorflow as tf
from tensorflow.keras import Sequential
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, LSTM, Embedding, Reshape
import urllib.request
import tensorflow_datasets as tfds
import unidecode

print(tf.__version__)

url="https://raw.githubusercontent.com/tlkh/text-emotion-classification/master/data.csv"
urllib.request.urlretrieve(url, "data.csv")
sentence=[]
sentiment=[]
texts=[]
with open("data.csv") as csvfile:
    reader = csv.reader(csvfile)
    for row in reader:
        texts.append(row)
print(texts[12])
random.shuffle(texts)
for row in texts:
        sentence.append(row[0])
        sentiment.append(int(row[1]))
# neutral, happy, sad, anger, hate.

token =  tfds.features.text.Tokenizer()
vocab = [token.tokenize(x) for x in sentence]
vocab = list(set([y for x in vocab for y in x]))
encoder = tfds.features.text.SubwordTextEncoder(vocab_list=vocab)
X_train = np.array([encoder.encode(x) for x in sentence])
print(X_train.shape)
print(len(np.unique(X_train)))

from tensorflow.keras.preprocessing import sequence
X_train = sequence.pad_sequences(X_train, maxlen=80)
max_features = 60000

tf.keras.backend.clear_session()  # For easy reset of notebook state.

model = Sequential()
model.add(Embedding(max_features, 128))
model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(5, activation='softmax'))
model.compile(loss='sparse_categorical_crossentropy',
              optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.9999, amsgrad=True),
              metrics=['accuracy'])
model.fit(X_train, np.array(sentiment), batch_size=64, epochs=5, validation_split=0.2, verbose=1)

model.save('sentany.h5', save_format='tf')