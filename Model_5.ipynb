{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "jwK61WhjJtDe",
    "outputId": "6d406b33-4d84-4105-e5a1-a559e63c2cb5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nagato/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import csv\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, LSTM, Embedding, Reshape\n",
    "print(\"Version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vjfaBpc_JtDr",
    "outputId": "dc0da105-ac15-4b55-d5f6-a1b21fed2946",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['traffic is down to a crawl on i 94 right now', '0']\n",
      "47288\n"
     ]
    }
   ],
   "source": [
    "# url=\"https://raw.githubusercontent.com/tlkh/text-emotion-classification/master/data.csv\"\n",
    "# import urllib.request\n",
    "# urllib.request.urlretrieve(url, \"traindata.csv\")\n",
    "sentence=[]\n",
    "sentiment=[]\n",
    "texts=[]\n",
    "with open(\"traindata.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        texts.append(row)\n",
    "            \n",
    "random.shuffle(texts)\n",
    "print(texts[12])\n",
    "for row in texts:\n",
    "    sentence.append(row[0])\n",
    "    sentiment.append(int(row[1]))\n",
    "# neutral, happy, sad, anger, hate\n",
    "print(len(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "NbC2reBkJtEe",
    "outputId": "a38a5535-b60c-408a-b8c8-3360f18d2196",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 20)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=40000)\n",
    "tokenizer.fit_on_texts(sentence)\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "sentence_token = tokenizer.texts_to_sequences(sentence)\n",
    "train_x = pad_sequences(sentence_token[:40000], maxlen=20)\n",
    "train_y= np.array(sentiment[:40000])\n",
    "test_x = pad_sequences(sentence_token[40000:], maxlen=20)\n",
    "test_y=np.array(sentiment[40000:])\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 931
    },
    "colab_type": "code",
    "id": "e4rI2cnkJtE_",
    "outputId": "4279b525-a145-4ba4-a78f-b0c1260e25b4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         7680000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 7,730,113\n",
      "Trainable params: 7,730,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 40000 samples, validate on 7288 samples\n",
      "Epoch 1/8\n",
      "40000/40000 [==============================] - 107s 3ms/sample - loss: 1.3804 - accuracy: 0.3388 - val_loss: 1.2736 - val_accuracy: 0.3605\n",
      "Epoch 2/8\n",
      "40000/40000 [==============================] - 107s 3ms/sample - loss: 1.2212 - accuracy: 0.3985 - val_loss: 1.1480 - val_accuracy: 0.4335\n",
      "Epoch 3/8\n",
      "40000/40000 [==============================] - 109s 3ms/sample - loss: 1.1326 - accuracy: 0.4522 - val_loss: 1.1060 - val_accuracy: 0.4974\n",
      "Epoch 4/8\n",
      "40000/40000 [==============================] - 108s 3ms/sample - loss: 1.0737 - accuracy: 0.5141 - val_loss: 1.0563 - val_accuracy: 0.5519\n",
      "Epoch 5/8\n",
      "40000/40000 [==============================] - 107s 3ms/sample - loss: 0.9964 - accuracy: 0.5752 - val_loss: 0.9939 - val_accuracy: 0.5901\n",
      "Epoch 6/8\n",
      "40000/40000 [==============================] - 107s 3ms/sample - loss: 0.9225 - accuracy: 0.6207 - val_loss: 0.9682 - val_accuracy: 0.5971\n",
      "Epoch 7/8\n",
      "40000/40000 [==============================] - 107s 3ms/sample - loss: 0.8637 - accuracy: 0.6544 - val_loss: 0.9628 - val_accuracy: 0.6029\n",
      "Epoch 8/8\n",
      "40000/40000 [==============================] - 106s 3ms/sample - loss: 0.8169 - accuracy: 0.6791 - val_loss: 0.9695 - val_accuracy: 0.6058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9c60ccd750>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "tf.keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Embedding(60000, 128))\n",
    "# model.add(tf.keras.layers.Conv1D(\n",
    "#                  100,\n",
    "#                  5,\n",
    "#                  padding='valid',\n",
    "#                  activation='sigmoid',\n",
    "#                  strides=1))\n",
    "model.add(LSTM(64, dropout=0.4, recurrent_dropout=0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "optim=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer=optim,\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(train_x, train_y , batch_size=32, epochs=8, validation_data=(test_x, test_y), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "colab_type": "code",
    "id": "DxcaU7ihJtFE",
    "outputId": "35ae4bd8-5ff2-4172-d875-3163b97beb9c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process(text):\n",
    "    text_p = tokenizer.texts_to_sequences([text])\n",
    "    processed = pad_sequences(text_p, maxlen=20)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"tokenizer_5.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(pad_sequences,handle )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save('Model_5.h5', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,  49,   9, 723]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process(\"Today is sunny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "ppp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
