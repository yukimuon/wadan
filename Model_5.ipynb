{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "jwK61WhjJtDe",
    "outputId": "6d406b33-4d84-4105-e5a1-a559e63c2cb5",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nagato/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/nagato/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import csv\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, LSTM, Embedding, Reshape\n",
    "print(\"Version: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vjfaBpc_JtDr",
    "outputId": "dc0da105-ac15-4b55-d5f6-a1b21fed2946",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['seriously bro wtf is wrong with you the hate and jealousy is disgusting grow up liberalism is amenta', '3']\n",
      "44138\n"
     ]
    }
   ],
   "source": [
    "url=\"https://raw.githubusercontent.com/tlkh/text-emotion-classification/master/data.csv\"\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(url, \"traindata.csv\")\n",
    "sentence=[]\n",
    "sentiment=[]\n",
    "texts=[]\n",
    "with open(\"traindata.csv\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        if row not in texts:\n",
    "            texts.append(row)\n",
    "random.shuffle(texts)\n",
    "print(texts[12])\n",
    "for row in texts:\n",
    "    sentence.append(row[0])\n",
    "    sentiment.append(int(row[1]))\n",
    "# neutral, happy, sad, anger, hate.\n",
    "print(len(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "NbC2reBkJtEe",
    "outputId": "a38a5535-b60c-408a-b8c8-3360f18d2196",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 30)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(sentence)\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "sentence_token = tokenizer.texts_to_sequences(sentence)\n",
    "train_x = pad_sequences(sentence_token[:40000], maxlen=30)\n",
    "train_y= np.array(sentiment[:40000])\n",
    "test_x = pad_sequences(sentence_token[30000:], maxlen=30)\n",
    "test_y=np.array(sentiment[30000:])\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 931
    },
    "colab_type": "code",
    "id": "e4rI2cnkJtE_",
    "outputId": "4279b525-a145-4ba4-a78f-b0c1260e25b4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         3200000   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 100)         64100     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 3,308,585\n",
      "Trainable params: 3,308,585\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /home/nagato/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 40000 samples, validate on 14138 samples\n",
      "Epoch 1/8\n",
      "40000/40000 [==============================] - 56s 1ms/sample - loss: 1.3813 - accuracy: 0.3266 - val_loss: 1.2981 - val_accuracy: 0.3965\n",
      "Epoch 2/8\n",
      "40000/40000 [==============================] - 55s 1ms/sample - loss: 1.2578 - accuracy: 0.4513 - val_loss: 1.1616 - val_accuracy: 0.5147\n",
      "Epoch 3/8\n",
      "40000/40000 [==============================] - 55s 1ms/sample - loss: 1.0891 - accuracy: 0.5670 - val_loss: 1.0167 - val_accuracy: 0.6102\n",
      "Epoch 4/8\n",
      "40000/40000 [==============================] - 55s 1ms/sample - loss: 0.9706 - accuracy: 0.6310 - val_loss: 0.9538 - val_accuracy: 0.6355\n",
      "Epoch 5/8\n",
      "40000/40000 [==============================] - 55s 1ms/sample - loss: 0.8894 - accuracy: 0.6697 - val_loss: 0.9056 - val_accuracy: 0.6594\n",
      "Epoch 6/8\n",
      "40000/40000 [==============================] - 56s 1ms/sample - loss: 0.8239 - accuracy: 0.7012 - val_loss: 0.8750 - val_accuracy: 0.6728\n",
      "Epoch 7/8\n",
      "40000/40000 [==============================] - 55s 1ms/sample - loss: 0.7706 - accuracy: 0.7254 - val_loss: 0.8479 - val_accuracy: 0.6901\n",
      "Epoch 8/8\n",
      "40000/40000 [==============================] - 55s 1ms/sample - loss: 0.7189 - accuracy: 0.7504 - val_loss: 0.8262 - val_accuracy: 0.7029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3d60534490>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "tf.keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Embedding(25000, 128))\n",
    "model.add(tf.keras.layers.Conv1D(\n",
    "                 100,\n",
    "                 5,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "optim=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.0001, beta_1=0.99, beta_2=0.9999)\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              optimizer=optim,\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(train_x, train_y , batch_size=32, epochs=8, validation_data=(test_x, test_y), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "colab_type": "code",
    "id": "DxcaU7ihJtFE",
    "outputId": "35ae4bd8-5ff2-4172-d875-3163b97beb9c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to sleep\n",
      "how to sleep neutral\n"
     ]
    }
   ],
   "source": [
    "output = [\"neutral\", \"happy\", \"sad\", \"anger\", \"hate\"]\n",
    "text=\"how to sleep\"\n",
    "text_p = tokenizer.texts_to_sequences([text])\n",
    "test = pad_sequences(text_p, maxlen=30)\n",
    "print(text)\n",
    "print(text,output[np.argmax(model.predict(pad_sequences(test)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zIMZ1aEmJtFK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save('Model_5_70val.h5', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"tokenizer_5.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(pad_sequences,handle )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "ppp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
